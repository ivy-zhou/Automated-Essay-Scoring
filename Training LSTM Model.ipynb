{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATASET_DIR = './data/'\n",
    "GLOVE_DIR = './glove.6B/'\n",
    "SAVE_DIR = './'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "X = pd.read_csv(os.path.join(DATASET_DIR, 'training_set_rel3.tsv'), sep='\\t', encoding='ISO-8859-1')\n",
    "y = X['domain1_score']\n",
    "X = X.dropna(axis=1)\n",
    "X = X.drop(columns=['rater1_domain1', 'rater2_domain1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum and Maximum Scores for each essay set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_scores = [-1, 2, 1, 0, 0, 0, 0, 0, 0]\n",
    "maximum_scores = [-1, 12, 6, 3, 3, 4, 4, 30, 60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will preprocess all essays and convert them to feature vectors so that they can be fed into the RNN.\n",
    "\n",
    "These are all helper functions used to clean the essays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "def essay_to_wordlist(essay_v, remove_stopwords):\n",
    "    \"\"\"Remove the tagged labels and word tokenize the sentence.\"\"\"\n",
    "    essay_v = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    words = essay_v.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return (words)\n",
    "\n",
    "def essay_to_sentences(essay_v, remove_stopwords):\n",
    "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(essay_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    num_words = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            num_words += 1\n",
    "            featureVec = np.add(featureVec,model[word])        \n",
    "    featureVec = np.divide(featureVec,num_words)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a 2-Layer LSTM Model. \n",
    "\n",
    "Note that instead of using sigmoid activation in the output layer we will use\n",
    "Relu since we are not normalising training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
    "from keras.models import Sequential, load_model, model_from_config\n",
    "import keras.backend as K\n",
    "\n",
    "def get_model():\n",
    "    \"\"\"Define the model.\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model on the dataset.\n",
    "\n",
    "We will use 5-Fold Cross Validation and measure the Quadratic Weighted Kappa for each fold.\n",
    "We will then calculate Average Kappa for all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ronitmankad/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10380/10380 [==============================] - 6s 601us/step - loss: 63.5235 - mean_absolute_error: 4.3085\n",
      "Epoch 2/50\n",
      "10380/10380 [==============================] - 4s 402us/step - loss: 38.5016 - mean_absolute_error: 3.4547\n",
      "Epoch 3/50\n",
      "10380/10380 [==============================] - 4s 406us/step - loss: 32.6369 - mean_absolute_error: 3.3775\n",
      "Epoch 4/50\n",
      "10380/10380 [==============================] - 4s 405us/step - loss: 30.2402 - mean_absolute_error: 3.3352\n",
      "Epoch 5/50\n",
      "10380/10380 [==============================] - 4s 402us/step - loss: 28.8526 - mean_absolute_error: 3.2857\n",
      "Epoch 6/50\n",
      "10380/10380 [==============================] - 4s 399us/step - loss: 27.0931 - mean_absolute_error: 3.1558\n",
      "Epoch 7/50\n",
      "10380/10380 [==============================] - 4s 400us/step - loss: 25.9112 - mean_absolute_error: 3.0514\n",
      "Epoch 8/50\n",
      "10380/10380 [==============================] - 4s 401us/step - loss: 24.2077 - mean_absolute_error: 2.8713\n",
      "Epoch 9/50\n",
      "10380/10380 [==============================] - 4s 405us/step - loss: 21.3049 - mean_absolute_error: 2.6915\n",
      "Epoch 10/50\n",
      "10380/10380 [==============================] - 5s 471us/step - loss: 18.6645 - mean_absolute_error: 2.5227\n",
      "Epoch 11/50\n",
      "10380/10380 [==============================] - 5s 481us/step - loss: 17.0862 - mean_absolute_error: 2.3953\n",
      "Epoch 12/50\n",
      "10380/10380 [==============================] - 5s 469us/step - loss: 16.5515 - mean_absolute_error: 2.3348\n",
      "Epoch 13/50\n",
      "10380/10380 [==============================] - 5s 471us/step - loss: 15.5819 - mean_absolute_error: 2.2491\n",
      "Epoch 14/50\n",
      "10380/10380 [==============================] - 5s 477us/step - loss: 14.2605 - mean_absolute_error: 2.1680\n",
      "Epoch 15/50\n",
      "10380/10380 [==============================] - 5s 476us/step - loss: 13.9900 - mean_absolute_error: 2.1280\n",
      "Epoch 16/50\n",
      "10380/10380 [==============================] - 5s 475us/step - loss: 13.4193 - mean_absolute_error: 2.1063\n",
      "Epoch 17/50\n",
      "10380/10380 [==============================] - 5s 480us/step - loss: 12.8282 - mean_absolute_error: 2.0642\n",
      "Epoch 18/50\n",
      "10380/10380 [==============================] - 5s 475us/step - loss: 12.9203 - mean_absolute_error: 2.0395\n",
      "Epoch 19/50\n",
      "10380/10380 [==============================] - 5s 496us/step - loss: 11.9574 - mean_absolute_error: 1.9789\n",
      "Epoch 20/50\n",
      "10380/10380 [==============================] - 5s 480us/step - loss: 11.8786 - mean_absolute_error: 1.9670\n",
      "Epoch 21/50\n",
      "10380/10380 [==============================] - 5s 476us/step - loss: 11.2761 - mean_absolute_error: 1.9160\n",
      "Epoch 22/50\n",
      "10380/10380 [==============================] - 5s 478us/step - loss: 11.4523 - mean_absolute_error: 1.9147\n",
      "Epoch 23/50\n",
      "10380/10380 [==============================] - 5s 481us/step - loss: 11.3838 - mean_absolute_error: 1.8938\n",
      "Epoch 24/50\n",
      "10380/10380 [==============================] - 5s 487us/step - loss: 10.6780 - mean_absolute_error: 1.8410\n",
      "Epoch 25/50\n",
      "10380/10380 [==============================] - 5s 489us/step - loss: 10.8487 - mean_absolute_error: 1.8455\n",
      "Epoch 26/50\n",
      "10380/10380 [==============================] - 5s 488us/step - loss: 10.2106 - mean_absolute_error: 1.8042\n",
      "Epoch 27/50\n",
      "10380/10380 [==============================] - 5s 496us/step - loss: 10.2350 - mean_absolute_error: 1.7975\n",
      "Epoch 28/50\n",
      "10380/10380 [==============================] - 5s 485us/step - loss: 9.9869 - mean_absolute_error: 1.7642\n",
      "Epoch 29/50\n",
      "10380/10380 [==============================] - 5s 486us/step - loss: 9.8490 - mean_absolute_error: 1.7526\n",
      "Epoch 30/50\n",
      "10380/10380 [==============================] - 5s 486us/step - loss: 9.6549 - mean_absolute_error: 1.7326\n",
      "Epoch 31/50\n",
      "10380/10380 [==============================] - 5s 490us/step - loss: 9.8022 - mean_absolute_error: 1.7378\n",
      "Epoch 32/50\n",
      "10380/10380 [==============================] - 5s 500us/step - loss: 9.8464 - mean_absolute_error: 1.7237\n",
      "Epoch 33/50\n",
      "10380/10380 [==============================] - 5s 494us/step - loss: 10.1569 - mean_absolute_error: 1.7463\n",
      "Epoch 34/50\n",
      "10380/10380 [==============================] - 5s 487us/step - loss: 9.1788 - mean_absolute_error: 1.6925\n",
      "Epoch 35/50\n",
      "10380/10380 [==============================] - 5s 512us/step - loss: 9.0076 - mean_absolute_error: 1.6951\n",
      "Epoch 36/50\n",
      "10380/10380 [==============================] - 5s 487us/step - loss: 9.0089 - mean_absolute_error: 1.6783\n",
      "Epoch 37/50\n",
      "10380/10380 [==============================] - 5s 496us/step - loss: 8.4260 - mean_absolute_error: 1.6397\n",
      "Epoch 38/50\n",
      "10380/10380 [==============================] - 5s 507us/step - loss: 8.7338 - mean_absolute_error: 1.6523\n",
      "Epoch 39/50\n",
      "10380/10380 [==============================] - 5s 498us/step - loss: 8.6461 - mean_absolute_error: 1.6494\n",
      "Epoch 40/50\n",
      "10380/10380 [==============================] - 5s 500us/step - loss: 8.7413 - mean_absolute_error: 1.6475\n",
      "Epoch 41/50\n",
      "10380/10380 [==============================] - 5s 497us/step - loss: 8.5590 - mean_absolute_error: 1.6373\n",
      "Epoch 42/50\n",
      "10380/10380 [==============================] - 5s 487us/step - loss: 8.7883 - mean_absolute_error: 1.6457\n",
      "Epoch 43/50\n",
      "10380/10380 [==============================] - 5s 486us/step - loss: 8.2834 - mean_absolute_error: 1.6170\n",
      "Epoch 44/50\n",
      "10380/10380 [==============================] - 5s 495us/step - loss: 8.4489 - mean_absolute_error: 1.6228\n",
      "Epoch 45/50\n",
      "10380/10380 [==============================] - 5s 491us/step - loss: 8.4475 - mean_absolute_error: 1.6096\n",
      "Epoch 46/50\n",
      "10380/10380 [==============================] - 5s 505us/step - loss: 8.0236 - mean_absolute_error: 1.5914\n",
      "Epoch 47/50\n",
      "10380/10380 [==============================] - 5s 493us/step - loss: 8.2755 - mean_absolute_error: 1.6129\n",
      "Epoch 48/50\n",
      "10380/10380 [==============================] - 5s 491us/step - loss: 8.3037 - mean_absolute_error: 1.5814\n",
      "Epoch 49/50\n",
      "10380/10380 [==============================] - 5s 490us/step - loss: 8.6168 - mean_absolute_error: 1.5995\n",
      "Epoch 50/50\n",
      "10380/10380 [==============================] - 5s 493us/step - loss: 8.4063 - mean_absolute_error: 1.5982\n",
      "Kappa Score: 0.9613444398855562\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 8s 723us/step - loss: 62.2980 - mean_absolute_error: 4.2575\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 506us/step - loss: 36.9081 - mean_absolute_error: 3.4606\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 506us/step - loss: 31.8027 - mean_absolute_error: 3.4013\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 5s 438us/step - loss: 29.4525 - mean_absolute_error: 3.3367\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 441us/step - loss: 27.6676 - mean_absolute_error: 3.2650\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 26.7322 - mean_absolute_error: 3.1840\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 5s 447us/step - loss: 25.1847 - mean_absolute_error: 3.0235\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 24.4046 - mean_absolute_error: 2.8881\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 5s 444us/step - loss: 22.0171 - mean_absolute_error: 2.7358\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 447us/step - loss: 19.3726 - mean_absolute_error: 2.5699\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 443us/step - loss: 16.9303 - mean_absolute_error: 2.3903\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 448us/step - loss: 15.3077 - mean_absolute_error: 2.2563\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 446us/step - loss: 14.9769 - mean_absolute_error: 2.2163\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 5s 450us/step - loss: 13.7733 - mean_absolute_error: 2.1543\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 13.2371 - mean_absolute_error: 2.1229\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 445us/step - loss: 12.9251 - mean_absolute_error: 2.0820\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 447us/step - loss: 12.6702 - mean_absolute_error: 2.0445\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 12.2949 - mean_absolute_error: 2.0036\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 11.7786 - mean_absolute_error: 1.9614\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 12.2178 - mean_absolute_error: 1.9645\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 11.7004 - mean_absolute_error: 1.9419\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 11.3668 - mean_absolute_error: 1.9114\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 452us/step - loss: 11.3117 - mean_absolute_error: 1.8967\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 5s 449us/step - loss: 10.5058 - mean_absolute_error: 1.8363\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 5s 458us/step - loss: 10.6058 - mean_absolute_error: 1.8325\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 10.0056 - mean_absolute_error: 1.7887\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 10.2886 - mean_absolute_error: 1.7926\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 10.0554 - mean_absolute_error: 1.7655\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 5s 459us/step - loss: 10.1119 - mean_absolute_error: 1.7643\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 9.6685 - mean_absolute_error: 1.7534\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 9.7459 - mean_absolute_error: 1.7405\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 9.3286 - mean_absolute_error: 1.7137\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 5s 498us/step - loss: 9.6981 - mean_absolute_error: 1.7241\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 5s 481us/step - loss: 9.3469 - mean_absolute_error: 1.7090\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 9.0990 - mean_absolute_error: 1.6880\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 9.0683 - mean_absolute_error: 1.6725\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 5s 483us/step - loss: 9.0441 - mean_absolute_error: 1.6716\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 5s 487us/step - loss: 8.7532 - mean_absolute_error: 1.6419 1s - loss: 8.7212 - \n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 5s 488us/step - loss: 8.9524 - mean_absolute_error: 1.6685\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 490us/step - loss: 8.4924 - mean_absolute_error: 1.6284\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 492us/step - loss: 8.7462 - mean_absolute_error: 1.6474\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 5s 492us/step - loss: 8.4404 - mean_absolute_error: 1.6222\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 8.6403 - mean_absolute_error: 1.6335\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 8.4331 - mean_absolute_error: 1.6135\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 487us/step - loss: 8.0298 - mean_absolute_error: 1.6018\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 4s 400us/step - loss: 8.1244 - mean_absolute_error: 1.5928\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 4s 406us/step - loss: 8.2598 - mean_absolute_error: 1.5919\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 4s 404us/step - loss: 8.2951 - mean_absolute_error: 1.5953\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 516us/step - loss: 8.2722 - mean_absolute_error: 1.5991\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 482us/step - loss: 8.2591 - mean_absolute_error: 1.5993\n",
      "Kappa Score: 0.9589832380634941\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 8s 742us/step - loss: 62.5675 - mean_absolute_error: 4.2637\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 507us/step - loss: 38.3448 - mean_absolute_error: 3.4645\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 507us/step - loss: 32.6267 - mean_absolute_error: 3.3669\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 5s 504us/step - loss: 30.1692 - mean_absolute_error: 3.3103\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 502us/step - loss: 28.7610 - mean_absolute_error: 3.2371\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 5s 506us/step - loss: 27.9961 - mean_absolute_error: 3.1440\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 25.7321 - mean_absolute_error: 2.9703\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 521us/step - loss: 22.0224 - mean_absolute_error: 2.7591\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 6s 536us/step - loss: 19.8124 - mean_absolute_error: 2.6059\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 18.1588 - mean_absolute_error: 2.4854\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 6s 596us/step - loss: 16.7148 - mean_absolute_error: 2.3875\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 434us/step - loss: 16.1785 - mean_absolute_error: 2.3219\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 486us/step - loss: 14.8489 - mean_absolute_error: 2.2284\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 4s 431us/step - loss: 14.3435 - mean_absolute_error: 2.1928\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 4s 432us/step - loss: 13.7165 - mean_absolute_error: 2.1590\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 6s 547us/step - loss: 13.3761 - mean_absolute_error: 2.0890\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 484us/step - loss: 12.6187 - mean_absolute_error: 2.0184\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 5s 469us/step - loss: 12.5590 - mean_absolute_error: 2.0113\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 5s 468us/step - loss: 11.9494 - mean_absolute_error: 1.9737\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 454us/step - loss: 11.9072 - mean_absolute_error: 1.9554\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 4s 419us/step - loss: 11.8927 - mean_absolute_error: 1.9263\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 448us/step - loss: 11.4953 - mean_absolute_error: 1.8964\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 11.5313 - mean_absolute_error: 1.8920\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 5s 439us/step - loss: 10.7838 - mean_absolute_error: 1.8527\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 4s 424us/step - loss: 10.5869 - mean_absolute_error: 1.8215\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 441us/step - loss: 10.3974 - mean_absolute_error: 1.8020\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 444us/step - loss: 9.4939 - mean_absolute_error: 1.7357\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 4s 428us/step - loss: 10.0305 - mean_absolute_error: 1.7451\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 10.0401 - mean_absolute_error: 1.7483\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 443us/step - loss: 9.4818 - mean_absolute_error: 1.7133\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 4s 420us/step - loss: 8.8647 - mean_absolute_error: 1.6773\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 4s 424us/step - loss: 9.5378 - mean_absolute_error: 1.7099\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 5s 439us/step - loss: 9.0718 - mean_absolute_error: 1.6817\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 4s 420us/step - loss: 9.3776 - mean_absolute_error: 1.6999\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 467us/step - loss: 9.1884 - mean_absolute_error: 1.6775\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 4s 402us/step - loss: 9.0791 - mean_absolute_error: 1.6763\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 4s 403us/step - loss: 9.1158 - mean_absolute_error: 1.6657\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 4s 414us/step - loss: 9.1464 - mean_absolute_error: 1.6648\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 4s 424us/step - loss: 9.3851 - mean_absolute_error: 1.6691\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 507us/step - loss: 8.4198 - mean_absolute_error: 1.6144\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 500us/step - loss: 8.9949 - mean_absolute_error: 1.6546\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 6s 546us/step - loss: 8.4026 - mean_absolute_error: 1.6071\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 6s 552us/step - loss: 9.0455 - mean_absolute_error: 1.6385\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 6s 598us/step - loss: 8.8043 - mean_absolute_error: 1.6247\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 6s 580us/step - loss: 9.0148 - mean_absolute_error: 1.6404\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 6s 591us/step - loss: 8.4393 - mean_absolute_error: 1.5798\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 8.4115 - mean_absolute_error: 1.5962\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 521us/step - loss: 8.3039 - mean_absolute_error: 1.5980\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 495us/step - loss: 9.0333 - mean_absolute_error: 1.6192\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 469us/step - loss: 8.3252 - mean_absolute_error: 1.5787\n",
      "Kappa Score: 0.9618648391087394\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 9s 847us/step - loss: 59.7070 - mean_absolute_error: 4.2050\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 6s 555us/step - loss: 38.0471 - mean_absolute_error: 3.4805\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 519us/step - loss: 33.5351 - mean_absolute_error: 3.4316\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 6s 552us/step - loss: 30.5502 - mean_absolute_error: 3.3712\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 5s 510us/step - loss: 28.7989 - mean_absolute_error: 3.2883\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 7s 639us/step - loss: 28.5260 - mean_absolute_error: 3.2329\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 5s 470us/step - loss: 26.5483 - mean_absolute_error: 3.0610\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 24.6949 - mean_absolute_error: 2.8993\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 5s 460us/step - loss: 21.8455 - mean_absolute_error: 2.7113\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 455us/step - loss: 20.1272 - mean_absolute_error: 2.5862\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 451us/step - loss: 19.1692 - mean_absolute_error: 2.5056\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 450us/step - loss: 17.5118 - mean_absolute_error: 2.3850\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 454us/step - loss: 16.7526 - mean_absolute_error: 2.3295\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 6s 541us/step - loss: 16.2574 - mean_absolute_error: 2.2811\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 6s 585us/step - loss: 15.6072 - mean_absolute_error: 2.2214\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 14.9989 - mean_absolute_error: 2.1690\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 461us/step - loss: 14.8320 - mean_absolute_error: 2.1662\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 6s 531us/step - loss: 13.1040 - mean_absolute_error: 2.0555\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 7s 677us/step - loss: 12.6551 - mean_absolute_error: 2.0237\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 510us/step - loss: 12.3173 - mean_absolute_error: 2.0013\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 5s 463us/step - loss: 11.6261 - mean_absolute_error: 1.9586\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 501us/step - loss: 11.3161 - mean_absolute_error: 1.9089\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 440us/step - loss: 11.7520 - mean_absolute_error: 1.9279\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 4s 428us/step - loss: 11.1106 - mean_absolute_error: 1.8810\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 4s 414us/step - loss: 11.0889 - mean_absolute_error: 1.8581\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 4s 430us/step - loss: 10.9807 - mean_absolute_error: 1.8435\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 4s 421us/step - loss: 10.9244 - mean_absolute_error: 1.8338\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 4s 400us/step - loss: 10.6652 - mean_absolute_error: 1.7977\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 4s 419us/step - loss: 10.0984 - mean_absolute_error: 1.7716\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 4s 401us/step - loss: 10.0962 - mean_absolute_error: 1.7613\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 10.0946 - mean_absolute_error: 1.7547\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 4s 407us/step - loss: 9.8874 - mean_absolute_error: 1.7351\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 6s 550us/step - loss: 9.7172 - mean_absolute_error: 1.7241\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 7s 634us/step - loss: 9.4290 - mean_absolute_error: 1.6996\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 6s 612us/step - loss: 9.6284 - mean_absolute_error: 1.7127\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 6s 536us/step - loss: 9.5775 - mean_absolute_error: 1.7034\n",
      "Epoch 37/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 9.5176 - mean_absolute_error: 1.6929\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 6s 575us/step - loss: 9.4747 - mean_absolute_error: 1.6902\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 6s 591us/step - loss: 9.2118 - mean_absolute_error: 1.6689\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 9.0569 - mean_absolute_error: 1.6607\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 8.7025 - mean_absolute_error: 1.6405\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 5s 494us/step - loss: 8.9474 - mean_absolute_error: 1.6552\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 5s 466us/step - loss: 8.6041 - mean_absolute_error: 1.6390\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 512us/step - loss: 8.4721 - mean_absolute_error: 1.6096\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.8245 - mean_absolute_error: 1.6373\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 8.8140 - mean_absolute_error: 1.6371\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 472us/step - loss: 8.8156 - mean_absolute_error: 1.6405\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 486us/step - loss: 8.8260 - mean_absolute_error: 1.6162\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 472us/step - loss: 8.4901 - mean_absolute_error: 1.6138\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 475us/step - loss: 8.2818 - mean_absolute_error: 1.6037\n",
      "Kappa Score: 0.9654185652735067\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 1, 300)            721200    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "10381/10381 [==============================] - 9s 856us/step - loss: 66.8658 - mean_absolute_error: 4.4002\n",
      "Epoch 2/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 39.8854 - mean_absolute_error: 3.5374\n",
      "Epoch 3/50\n",
      "10381/10381 [==============================] - 5s 492us/step - loss: 33.5379 - mean_absolute_error: 3.4505\n",
      "Epoch 4/50\n",
      "10381/10381 [==============================] - 7s 652us/step - loss: 30.7586 - mean_absolute_error: 3.3854\n",
      "Epoch 5/50\n",
      "10381/10381 [==============================] - 7s 694us/step - loss: 29.5095 - mean_absolute_error: 3.3351\n",
      "Epoch 6/50\n",
      "10381/10381 [==============================] - 6s 622us/step - loss: 27.9794 - mean_absolute_error: 3.2122\n",
      "Epoch 7/50\n",
      "10381/10381 [==============================] - 7s 645us/step - loss: 26.7502 - mean_absolute_error: 3.1037\n",
      "Epoch 8/50\n",
      "10381/10381 [==============================] - 6s 597us/step - loss: 24.9557 - mean_absolute_error: 2.9391\n",
      "Epoch 9/50\n",
      "10381/10381 [==============================] - 6s 551us/step - loss: 23.5008 - mean_absolute_error: 2.8150\n",
      "Epoch 10/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 20.7775 - mean_absolute_error: 2.6662\n",
      "Epoch 11/50\n",
      "10381/10381 [==============================] - 5s 509us/step - loss: 18.1789 - mean_absolute_error: 2.4703\n",
      "Epoch 12/50\n",
      "10381/10381 [==============================] - 5s 529us/step - loss: 16.9959 - mean_absolute_error: 2.3944\n",
      "Epoch 13/50\n",
      "10381/10381 [==============================] - 5s 480us/step - loss: 16.4161 - mean_absolute_error: 2.3150\n",
      "Epoch 14/50\n",
      "10381/10381 [==============================] - 5s 480us/step - loss: 15.1381 - mean_absolute_error: 2.2450\n",
      "Epoch 15/50\n",
      "10381/10381 [==============================] - 5s 474us/step - loss: 14.1863 - mean_absolute_error: 2.1797\n",
      "Epoch 16/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 14.2240 - mean_absolute_error: 2.1662\n",
      "Epoch 17/50\n",
      "10381/10381 [==============================] - 5s 485us/step - loss: 14.3227 - mean_absolute_error: 2.1571\n",
      "Epoch 18/50\n",
      "10381/10381 [==============================] - 5s 503us/step - loss: 13.6644 - mean_absolute_error: 2.1185\n",
      "Epoch 19/50\n",
      "10381/10381 [==============================] - 5s 487us/step - loss: 12.6964 - mean_absolute_error: 2.0335\n",
      "Epoch 20/50\n",
      "10381/10381 [==============================] - 5s 491us/step - loss: 12.4478 - mean_absolute_error: 2.0097\n",
      "Epoch 21/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 12.3681 - mean_absolute_error: 1.9919\n",
      "Epoch 22/50\n",
      "10381/10381 [==============================] - 5s 482us/step - loss: 11.7553 - mean_absolute_error: 1.9568\n",
      "Epoch 23/50\n",
      "10381/10381 [==============================] - 5s 493us/step - loss: 11.1410 - mean_absolute_error: 1.9098\n",
      "Epoch 24/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 11.8557 - mean_absolute_error: 1.9389\n",
      "Epoch 25/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 10.9873 - mean_absolute_error: 1.8905\n",
      "Epoch 26/50\n",
      "10381/10381 [==============================] - 5s 502us/step - loss: 10.7885 - mean_absolute_error: 1.8577\n",
      "Epoch 27/50\n",
      "10381/10381 [==============================] - 5s 486us/step - loss: 10.5365 - mean_absolute_error: 1.8211\n",
      "Epoch 28/50\n",
      "10381/10381 [==============================] - 5s 471us/step - loss: 10.9418 - mean_absolute_error: 1.8321\n",
      "Epoch 29/50\n",
      "10381/10381 [==============================] - 5s 489us/step - loss: 10.5133 - mean_absolute_error: 1.8128\n",
      "Epoch 30/50\n",
      "10381/10381 [==============================] - 5s 522us/step - loss: 10.0106 - mean_absolute_error: 1.7629\n",
      "Epoch 31/50\n",
      "10381/10381 [==============================] - 6s 544us/step - loss: 9.6048 - mean_absolute_error: 1.7390\n",
      "Epoch 32/50\n",
      "10381/10381 [==============================] - 6s 572us/step - loss: 10.0271 - mean_absolute_error: 1.7459\n",
      "Epoch 33/50\n",
      "10381/10381 [==============================] - 6s 597us/step - loss: 9.5344 - mean_absolute_error: 1.7295\n",
      "Epoch 34/50\n",
      "10381/10381 [==============================] - 6s 592us/step - loss: 9.5514 - mean_absolute_error: 1.7252\n",
      "Epoch 35/50\n",
      "10381/10381 [==============================] - 5s 521us/step - loss: 9.5900 - mean_absolute_error: 1.7174\n",
      "Epoch 36/50\n",
      "10381/10381 [==============================] - 5s 505us/step - loss: 9.2818 - mean_absolute_error: 1.7096\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10381/10381 [==============================] - 5s 482us/step - loss: 9.1404 - mean_absolute_error: 1.6770 2s - lo\n",
      "Epoch 38/50\n",
      "10381/10381 [==============================] - 5s 482us/step - loss: 9.1458 - mean_absolute_error: 1.6917\n",
      "Epoch 39/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.8663 - mean_absolute_error: 1.6622\n",
      "Epoch 40/50\n",
      "10381/10381 [==============================] - 4s 429us/step - loss: 9.2812 - mean_absolute_error: 1.6708\n",
      "Epoch 41/50\n",
      "10381/10381 [==============================] - 4s 427us/step - loss: 8.7367 - mean_absolute_error: 1.6541\n",
      "Epoch 42/50\n",
      "10381/10381 [==============================] - 4s 423us/step - loss: 9.1140 - mean_absolute_error: 1.6701\n",
      "Epoch 43/50\n",
      "10381/10381 [==============================] - 6s 577us/step - loss: 8.7978 - mean_absolute_error: 1.6674\n",
      "Epoch 44/50\n",
      "10381/10381 [==============================] - 5s 481us/step - loss: 8.5478 - mean_absolute_error: 1.6401\n",
      "Epoch 45/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.8018 - mean_absolute_error: 1.6453\n",
      "Epoch 46/50\n",
      "10381/10381 [==============================] - 5s 478us/step - loss: 8.5641 - mean_absolute_error: 1.6328\n",
      "Epoch 47/50\n",
      "10381/10381 [==============================] - 5s 481us/step - loss: 8.4396 - mean_absolute_error: 1.6151\n",
      "Epoch 48/50\n",
      "10381/10381 [==============================] - 5s 477us/step - loss: 8.4194 - mean_absolute_error: 1.6171\n",
      "Epoch 49/50\n",
      "10381/10381 [==============================] - 5s 475us/step - loss: 8.5554 - mean_absolute_error: 1.6230\n",
      "Epoch 50/50\n",
      "10381/10381 [==============================] - 5s 476us/step - loss: 8.3460 - mean_absolute_error: 1.6109\n",
      "Kappa Score: 0.9587622776495751\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "cv = KFold(len(X), n_folds=5, shuffle=True)\n",
    "results = []\n",
    "y_pred_list = []\n",
    "\n",
    "count = 1\n",
    "for traincv, testcv in cv:\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "    \n",
    "    train_essays = X_train['essay']\n",
    "    test_essays = X_test['essay']\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    for essay in train_essays:\n",
    "            # Obtaining all sentences from the training essays.\n",
    "            sentences += essay_to_sentences(essay, remove_stopwords = True)\n",
    "            \n",
    "    # Initializing variables for word2vec model.\n",
    "    num_features = 300 \n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    print(\"Training Word2Vec Model...\")\n",
    "    model = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    clean_train_essays = []\n",
    "    \n",
    "    # Generate training and testing data word vectors.\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(essay_to_wordlist(essay_v, remove_stopwords=True))\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    \n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(essay_to_wordlist( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    lstm_model = get_model()\n",
    "    lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=50)\n",
    "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "    \n",
    "    # Save any one of the 8 models.\n",
    "    if count == 5:\n",
    "         lstm_model.save('./model_weights/final_lstm.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "    \n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "\n",
    "    count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Avg. Kappa Score is 0.961 which is the highest we have ever seen on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Kappa score after a 5-fold cross validation:  0.9613\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
